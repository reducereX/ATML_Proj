# Logit-Weighted Supervised Contrastive Representation Distillation (LW-SupCRD)

## Project Overview
This project implements and evaluates **Logit-Weighted Supervised Contrastive Representation Distillation (LW-SupCRD)**, a novel knowledge distillation framework that combines supervised contrastive learning with teacher-guided semantic weighting on CIFAR-100.

**Key Innovation:** Uses teacher logits to semantically weight contrastive forces, achieving superior representation learning compared to standard supervised contrastive methods.

## Setup Instructions

### 1. Download Pre-trained Model Weights
**All pre-trained models are available on Google Drive:**

ðŸ”— **[Download Models Here](https://drive.google.com/drive/u/0/folders/1oyiYnKOiP7AYYiT7ik0Tq591gtPCJVAo)**

### 2. Create Directory Structure
Create a `pth_models/` folder at the project root:

```bash
mkdir pth_models
```

Your directory structure should look like:

```
ATML_Proj/
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ DeSupCon.ipynb
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”‚
â”œâ”€â”€ proposal/
â”‚   â”œâ”€â”€ Decoupled Feature Distillation Idea Explanation.pdf
â”‚   â””â”€â”€ prop.tex (+ LaTeX auxiliary files)
â”‚
â”œâ”€â”€ json_results/
â”‚   â”œâ”€â”€ comprehensive_results_resnet18_cifar100.json
â”‚   â””â”€â”€ training_logs/
â”‚       â”œâ”€â”€ teacher_resnet50_cifar100.json
â”‚       â”œâ”€â”€ student_baseline_supcon_resnet18_cifar100.json
â”‚       â”œâ”€â”€ student_baseline_crd_resnet18_cifar100.json
â”‚       â”œâ”€â”€ student_undistilled_resnet18_cifar100.json
â”‚       â”œâ”€â”€ student_alpha_*.json (Î± sweep experiments)
â”‚       â”œâ”€â”€ student_*_beta_*.json (Î² sweep experiments)
â”‚       â”œâ”€â”€ student_*_temp_*.json (temperature sweep)
â”‚       â””â”€â”€ student_hybrid_lambda_*.json (hybrid loss experiments)
â”‚
â”œâ”€â”€ plots/
â”‚   â”œâ”€â”€ t-SNE visualizations (tsne_*.png)
â”‚   â”œâ”€â”€ 3D hypersphere distributions (*_hypersphere.html)
â”‚   â””â”€â”€ Alignment & Uniformity analyses (*_alignment.png)
â”‚
â””â”€â”€ pth_models/
    â”œâ”€â”€ teacher_resnet50_cifar100.pth (80.75% acc)
    â”œâ”€â”€ teacher_resnet50_cifar100_with_projection.pth
    â”œâ”€â”€ student_baseline_supcon_resnet18_cifar100.pth (69.08%)
    â”œâ”€â”€ student_baseline_crd_resnet18_cifar100.pth (68.05%)
    â”œâ”€â”€ student_undistilled_resnet18_cifar100.pth (67.93%)
    â”œâ”€â”€ student_alpha_1.0_beta_10.0_temp_0.07_resnet18_cifar100.pth â­ (73.35% - BEST)
    â””â”€â”€ student_*_resnet18_cifar100.pth (various configurations)
```

### 3. Download Required Models

Download these essential models from Google Drive and place them in `pth_models/`:

#### Core Models (Required)
- `teacher_resnet50_cifar100.pth` - Teacher model (80.75% accuracy)
- `teacher_resnet50_cifar100_with_projection.pth` - Teacher with trained 64-dim cosine projection
- `student_baseline_supcon_resnet18_cifar100.pth` - Baseline SupCon student (69.08%)

#### Best Model (Recommended) ðŸ†
- `student_alpha_1.0_beta_10.0_temp_0.07_resnet18_cifar100.pth` - **73.35% accuracy** (best overall)

#### Baselines & Ablations (Optional)
- `student_baseline_crd_resnet18_cifar100.pth` - Baseline CRD (68.05%)
- `student_undistilled_resnet18_cifar100.pth` - Undistilled student (67.93%)
- Various Î±, Î², temperature, and hybrid configurations

---

## Results Summary

### **Main Results - Best Configurations**

| Method | Test Acc | Î” vs SupCon | Alignment â†“ | Uniformity â†“ | Key Features |
|--------|----------|-------------|-------------|--------------|--------------|
| **ðŸ† LW-SupCRD (Ï„=0.07)** | **73.35%** | **+4.27%** | 1.1990 | **-3.7104** | Best overall - optimal temperature |
| LW-SupCRD (Î±=1, Î²=10) | 73.19% | +4.11% | 1.1518 | **-3.7027** | Near-identical to Ï„=0.07 |
| Hybrid (Î»=0.3) | 72.58% | +3.50% | **0.6043** | -3.2880 | Best hybrid - severe overfitting |
| **Baseline SupCon** | 69.08% | - | **0.4377** | -2.5665 | Strong alignment, weak uniformity |
| Baseline CRD | 68.05% | -1.03% | 0.9008 | -2.2358 | Poor both metrics |
| Undistilled Student | 67.93% | -1.15% | 0.6631 | -1.7332 | Terrible uniformity |
| **Teacher (ResNet-50)** | 80.75% | +11.67% | **0.5928** | **-3.4649** | Reference upper bound |

**Key Takeaway:** LW-SupCRD achieves **73.35%** with best-in-class uniformity (**-3.7104**), even surpassing the teacher's uniformity (-3.4649), while maintaining competitive alignment for superior generalization.

---

### **Comprehensive Experimental Results**

#### 1. **Alpha (Î±) Sweep - Pull Force Weighting**
*Configuration: Î²=10, Ï„=0.07, adaptive Î²*

| Î± | Test Acc | Î” vs SupCon | Alignment â†“ | Uniformity â†“ | Observation |
|---|----------|-------------|-------------|--------------|-------------|
| **1.0** | **73.19%** | **+4.11%** | 1.1518 | **-3.7027** | âœ… Optimal balance |
| 2.0 | 71.78% | +2.70% | **1.1129** | -3.6744 | Tighter clusters â†’ worse uniformity |
| 5.0 | 70.67% | +1.59% | 1.1589 | -3.6712 | Over-clustering |
| 10.0 | 70.07% | +0.99% | 1.2754 | -3.6728 | Severe over-clustering |

**Finding:** Î±=1 optimal - higher Î± causes tighter clusters, sacrificing uniformity and causing overfitting.

---

#### 2. **Beta (Î²) Sweep - Push Force Strength**
*Configuration: Î±=1, Ï„=0.07, adaptive Î²*

| Î² | Test Acc | Î” vs SupCon | Alignment â†“ | Uniformity â†“ | Observation |
|---|----------|-------------|-------------|--------------|-------------|
| **10.0** | **73.19%** | **+4.11%** | **1.1518** | **-3.7027** | âœ… Optimal - strong push |
| 12.0 | 71.31% | +2.23% | 1.2068 | -3.6654 | Too strong â†’ degradation |
| 5.0 | 70.63% | +1.55% | 1.2487 | -3.6785 | Weak push â†’ poor separation |
| 1.0 | 70.46% | +1.38% | 1.1862 | -3.6390 | Very weak push |

**Finding:** Î²=10 optimal - balances strong class separation with stable training. Too high causes instability, too low fails to separate classes.

---

#### 3. **Temperature (Ï„) Sweep - Gradient Sharpness**
*Configuration: Î±=1, Î²=10, adaptive Î²*

| Ï„ | Test Acc | Î” vs SupCon | Alignment â†“ | Uniformity â†“ | Observation |
|---|----------|-------------|-------------|--------------|-------------|
| **0.07** | **73.35%** | **+4.27%** | 1.1990 | **-3.7104** | âœ… Optimal - balanced spread |
| 0.05 | 68.08% | -1.00% | 1.3503 | -3.6645 | Too sharp â†’ poor alignment |

**Finding:** Ï„=0.07 provides optimal gradient flow - Ï„=0.05 too sharp, only closest pairs contribute.

---

#### 4. **Hybrid Loss (Î») Sweep - SupCon + LW-SupCRD Mix**
*Formula: `L = Î» Ã— SupCon + (1-Î») Ã— LW-SupCRD`*
*Configuration: Î±=1, Î²=10, Ï„=0.07*

| Î» | Test Acc | Train Acc | Gap | Alignment â†“ | Uniformity â†“ | Observation |
|---|----------|-----------|-----|-------------|--------------|-------------|
| **0.3** | **72.58%** | 98.73% | **26.15%** | **0.6043** | -3.2880 | Best hybrid - severe overfitting |
| 0.5 | 72.07% | 98.92% | 26.85% | **0.5166** | -2.9451 | Worse overfitting |
| 0.7 | 71.57% | 98.25% | 26.68% | **0.4845** | -2.8290 | Poor uniformity |
| 0.9 | 70.69% | 95.40% | 24.71% | **0.4394** | -2.6273 | Approaching pure SupCon |

**Critical Finding:** All hybrids show massive overfitting (24-27% gap) despite excellent alignment. **Pure LW-SupCRD (73.35%) beats best hybrid (72.58%)** - adding SupCon only adds noise.

---

## Key Findings

### **1. The Alignment-Uniformity Trade-off for CIFAR-100** ðŸ“Š

For fine-grained classification (100 classes), **uniformity is more critical than tight alignment:**

**Best Methods (73%+):**
- Alignment: ~1.15-1.20 (moderate clusters)
- Uniformity: ~-3.70 (excellent spread)
- Strategy: Trade cluster tightness for class separation

**Worst Methods (68%-):**
- Alignment: ~0.44-0.66 (very tight clusters)
- Uniformity: ~-2.50 to -1.73 (poor spread)
- Problem: Over-clustering causes poor separation

**Counter-intuitive Insight:** Student's "worse" alignment (1.20 vs teacher's 0.59) actually helps generalization by maintaining better class separation on the hypersphere.

---

### **2. Hyperparameter Roles & Interactions**

**Î± (Pull Weight) - Semantic Confidence:**
- Controls cluster tightness via teacher probabilities
- Î±=1 optimal: Minimal semantic weighting
- Higher Î± â†’ tighter clusters â†’ worse uniformity â†’ overfitting
- Effect: Primarily degrades uniformity

**Î² (Push Weight) - Negative Force Strength:**
- Controls class separation strength
- Î²=10 optimal: Strong push forces
- Critical discovery: Affects **both** alignment AND uniformity simultaneously
- Unlike Î±, strong Î² improves both metrics

**Ï„ (Temperature) - Gradient Sharpness:**
- Controls exponential scaling in similarity
- Ï„=0.07 optimal: Balanced gradient flow
- Ï„=0.05 too sharp: Only nearest neighbors contribute
- Effect: Primarily affects uniformity

**Adaptive Î² - Curriculum Learning:**
- Early epochs (uncertain): Î²_eff = 1.25Î² (stronger push)
- Late epochs (confident): Î²_eff = 0.71Î² (weaker push)
- Provides natural hard negative mining

---

### **3. Why Hybrids Fail** âŒ

All hybrid losses (Î»=0.3 to 0.9) show:
- âœ“ Excellent alignment (0.44-0.60, like teacher)
- âœ— Poor uniformity (-2.6 to -3.3)
- âœ— Massive overfitting (24-27% train-test gap)
- âœ— Lower accuracy than pure LW-SupCRD

**Root Cause:** SupCon's pull-only forces create over-tight clusters, sacrificing the uniformity that LW-SupCRD's strong push forces (Î²=10) achieve.

**Conclusion:** Pure LW-SupCRD (73.35%) > Best Hybrid (72.58%)

---

### **4. Student Surpasses Teacher in Uniformity** ðŸŽ¯

| Metric | Teacher | Best Student | Observation |
|--------|---------|--------------|-------------|
| Alignment | **0.5928** | 1.1990 | Student 2Ã— looser |
| Uniformity | -3.4649 | **-3.7104** | Student 7% better |
| Accuracy | 80.75% | 73.35% | Reasonable gap |

**Key Insight:** Student trades alignment for uniformity and still outperforms all baselines significantly. The looser clusters + better spread = superior linear separability.

---

### **5. Gradient Normalization Critical** âš™ï¸

The `/Î±` normalization in the loss prevents gradient saturation:
- Without: Î±=2 causes exponentials ~exp(20) = 4.8Ã—10â¸
- With: Allows proper Î± scaling without optimization collapse
- Enables exploration of Î±>1 configurations

This fix was essential for all Î± sweep experiments to work.

---

## Technical Details

### Model Architecture
- **Teacher:** ResNet-50 (23.5M parameters, 80.75% accuracy)
- **Student:** ResNet-18 (11.2M parameters)
- **Projection:** 2048-dim backbone â†’ 64-dim contrastive space
- **Dataset:** CIFAR-100 (100 classes, 50k train / 10k test)
- **Training:** 50 epochs, batch size 128, Adam optimizer (lr=1e-3)

### Loss Functions

#### 1. **Baseline SupCon** (Khosla et al., 2020)
Standard supervised contrastive learning - pull positives only.

#### 2. **Baseline CRD** (Tian et al., 2020)
Contrastive Representation Distillation - instance matching.

#### 3. **LW-SupCRD** (Ours)
Logit-weighted supervised contrastive with adaptive forces:

```python
# Pull weight (semantic confidence)
w_pull = Î± Ã— p_teacher(correct_class)

# Push weight (inverse adaptive)
if adaptive_beta:
    Î²_effective = Î² / (p_target + 0.5)
    w_push = Î²_effective Ã— (1 - p_teacher(negative_class))
else:
    w_push = Î² Ã— (1 - p_teacher(negative_class))

# Gradient normalization
loss = -log((w_pull Ã— pos_exp) / (w_pull Ã— pos_exp + w_push Ã— neg_exp))
loss = loss / Î±  # CRITICAL: prevents gradient saturation
```

#### 4. **Hybrid Loss**
```python
L = Î» Ã— L_SupCon + (1 - Î») Ã— L_LW-SupCRD
```
Best: Î»=0.3, but still underperforms pure LW-SupCRD.

---

## Visualization & Analysis

### Alignment & Uniformity Metrics (Wang & Isola, 2020)

**Alignment Loss (â†“ better):**
```
L_align = E[||f(x) - f(x+)||Â²]
```
Measures positive pair distance - lower = tighter clusters.

**Uniformity Loss (â†“ better, more negative):**
```
L_uniform = log(E[exp(-2||f(x) - f(y)||Â²)])
```
Measures hypersphere coverage - more negative = better spread.

### Available Visualizations

All experiments include:
- **t-SNE plots:** 2D projection of learned representations (20 classes)
- **3D Hypersphere:** Interactive Plotly visualizations (`.html` files)
- **Alignment/Uniformity:** Comprehensive Wang & Isola analysis
- **Training logs:** JSON files with per-epoch metrics

---

## Dependencies

```bash
pip install torch torchvision
pip install numpy matplotlib scikit-learn scipy
pip install plotly  # For interactive 3D visualizations
pip install tqdm
```

## Usage

### Running the Notebook

1. Open `DeSupCon.ipynb` in Jupyter
2. Download required models from Google Drive
3. Place models in `pth_models/` directory
4. Run all cells sequentially

**Training Control:**
- Set `FORCE_RETRAIN = True` to retrain models (ignores cached weights)
- Set `FORCE_RETRAIN = False` to load pre-trained models (default)

### Loading Best Model

```python
import torch
from models import ModelWrapper

# Load best model
model = ModelWrapper(num_classes=100, arch='resnet18')
checkpoint = torch.load('pth_models/student_alpha_1.0_beta_10.0_temp_0.07_resnet18_cifar100.pth')
model.load_state_dict(checkpoint)
model.eval()

# Inference
with torch.no_grad():
    features, projections, logits = model(images)
```

---

## Experimental Protocol

### Teacher Training
1. Train ResNet-50 on CIFAR-100 â†’ 80.75% accuracy
2. Train cosine similarity projection head (2048â†’64D)
3. Joint training: projection adapts during student training (CRD-style)

### Student Training
1. Multi-view augmentation (2 views per sample)
2. Contrastive loss on encoder projections
3. Separate linear classifier on frozen features (standard evaluation)
4. 50 epochs, batch size 128, Adam (lr=1e-3)

### Comprehensive Analysis Per Experiment
- t-SNE visualizations (20 sample classes)
- 3D hypersphere distribution (interactive HTML)
- Wang & Isola alignment-uniformity metrics
- Intra/inter-class distance analysis
- Separation ratio computation
- Training curves (JSON logs)
- Model checkpointing for reproducibility

---

## Citation

If you use this code or findings in your research, please cite:

```bibtex
@misc{lw_supcrd2025,
  title={Logit-Weighted Supervised Contrastive Representation Distillation: 
         Achieving Superior Uniformity through Semantic Force Weighting},
  author={Ibrahim Murtaza, Jibran Mazhar, Muhammad Ahsan Salar Khan},
  year={2025},
  institution={Lahore University of Management Sciences (LUMS)},
  course={EE-5102/CS-6304: Advanced Topics in Machine Learning},
  instructor={Professor Muhammad Tahir},
  note={Best Configuration: Î±=1.0, Î²=10.0, Ï„=0.07 achieving 73.35% on CIFAR-100}
}
```

### Key References
- Khosla et al., "Supervised Contrastive Learning", NeurIPS 2020
- Wang & Isola, "Understanding Contrastive Representation Learning through Alignment and Uniformity on the Hypersphere", ICML 2020
- Tian et al., "Contrastive Representation Distillation", ICLR 2020

---

## Reproducibility

### Hardware
- **GPU:** RTX Pro 6000 Blackwell Edition
- **VRAM:** 96GB
- **Compute:** 119 TFLOPs
- **Training Time:** ~2-3 hours per configuration

### Random Seeds
All experiments use fixed random seeds for reproducibility:
```python
torch.manual_seed(42)
np.random.seed(42)
```

### Model Weights Distribution
All trained models available on Google Drive with:
- Model checkpoints (`.pth` files)
- Training logs (`.json` files)
- Comprehensive visualizations (`.png`, `.html`)

---

## Future Work

1. **Extended Architectures:** Test on deeper networks (ResNet-101, WideResNet)
2. **Larger Datasets:** Evaluate on ImageNet, iNaturalist
3. **Multi-Teacher:** Ensemble knowledge from multiple teachers
4. **Theoretical Analysis:** Formal proof of alignment-uniformity trade-off
5. **Publication:** Prepare for submission to WACV/BMVC

---

## Acknowledgments

- **Course Instructor:** Professor Muhammad Tahir
- **Team Members:** Ibrahim Murtaza, Jibran Mazhar, Muhammad Ahsan Salar Khan
- **Institution:** Lahore University of Management Sciences (LUMS)
- **Hardware Support:** RTX Pro 6000 Blackwell Edition (96GB VRAM)

Special thanks to:
- Khosla et al. for Supervised Contrastive Learning
- Wang & Isola for the alignment-uniformity framework
- Tian et al. for Contrastive Representation Distillation

---

## License
This project is for academic purposes as part of the ATML course at LUMS.

## Contact
For questions or issues, please open an issue on the repository or contact the team members.

---

**Last Updated:** December 23, 2025

**Status:** âœ… All experiments completed | ðŸ“Š Results finalized | ðŸŽ¯ Best model: 73.35% accuracy